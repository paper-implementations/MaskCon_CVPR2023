{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c0a3233b",
   "metadata": {
    "papermill": {
     "duration": 31.482213,
     "end_time": "2024-06-27T06:12:34.000007",
     "exception": false,
     "start_time": "2024-06-27T06:12:02.517794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bf68235a",
   "metadata": {
    "papermill": {
     "duration": 0.030657,
     "end_time": "2024-06-27T06:12:34.054147",
     "exception": false,
     "start_time": "2024-06-27T06:12:34.023490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--NO_TSNE'], dest='NO_TSNE', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Enable TSNE visualization', metavar=None)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for jupyter notebook set arguments\n",
    "parser = argparse.ArgumentParser(description='Masked contrastive learning.')\n",
    "args = argparse.Namespace(description='Masked contrastive learning.')\n",
    "\n",
    "# training config:\n",
    "parser.add_argument('--dataset', default='cifartoy_good', choices=['cifar100', 'cifartoy_bad', 'cifartoy_good', 'cars196', 'sop_split1', 'sop_split2', 'imagenet32'], type=str, help='train dataset')\n",
    "parser.add_argument('--data_path', default='./data', type=str, help='train dataset')\n",
    "\n",
    "# model configs: [Almost fixed for all experiments]\n",
    "parser.add_argument('--arch', default='resnet18')\n",
    "parser.add_argument('--dim', default=256, type=int, help='feature dimension')\n",
    "parser.add_argument('--K', default=8192, type=int, help='queue size; number of negative keys')\n",
    "parser.add_argument('--m', default=0.99, type=float, help='moco momentum of updating key encoder')\n",
    "parser.add_argument('--t0', default=0.1, type=float, help='softmax temperature for training')\n",
    "\n",
    "# train configs:\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.02, type=float, metavar='LR', help='initial learning rate', dest='lr')\n",
    "# parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs')\n",
    "parser.add_argument('--epochs', default=300, type=int, metavar='N', help='number of total epochs')\n",
    "parser.add_argument('--warm_up', default=5, type=int, metavar='N', help='number of warmup epochs')\n",
    "parser.add_argument('--batch_size', default=128, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "parser.add_argument('--aug_q', default='strong', type=str, help='augmentation strategy for query image')\n",
    "parser.add_argument('--aug_k', default='weak', type=str, help='augmentation strategy for key image')\n",
    "parser.add_argument('--gpu_id', default='0', type=str, help='gpuid')\n",
    "\n",
    "# method configs:\n",
    "parser.add_argument('--mode', default='maskcon', type=str, choices=['maskcon', 'grafit', 'coins'], help='training mode')\n",
    "\n",
    "# maskcon-specific hyperparameters:\n",
    "parser.add_argument('--w', default=0.5, type=float, help='weight of self-invariance')  # not-used if maskcon\n",
    "parser.add_argument('--t', default=0.05, type=float, help='softmax temperature weight for soft label')\n",
    "\n",
    "# logger configs\n",
    "# parser.add_argument('--wandb_id', default='logs',type=str, help='wandb user id')\n",
    "parser.add_argument('--logs', default='logs',type=str, help='log directory file name')\n",
    "parser.add_argument('--NO_TSNE', action='store_true', help='Enable TSNE visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "786fe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retrieval(encoder, test_loader, K, args, epoch, chunks=10, num_samples=200):\n",
    "    encoder.eval()\n",
    "    feature_bank, target_bank = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (image, _, fine_label) in enumerate(test_loader):\n",
    "            image = image.cuda(non_blocking=True)\n",
    "            label = fine_label.cuda(non_blocking=True)\n",
    "            output = encoder(image, feat=True)\n",
    "            feature_bank.append(output)\n",
    "            target_bank.append(label)\n",
    "        \n",
    "        feature = torch.cat(feature_bank, dim=0)\n",
    "        label = torch.cat(target_bank, dim=0).contiguous()\n",
    "    \n",
    "    label = label.unsqueeze(-1)\n",
    "    feat_norm = F.normalize(feature, dim=1)\n",
    "    split = torch.tensor(np.linspace(0, len(feat_norm), chunks + 1, dtype=int), dtype=torch.long).to(feature.device)\n",
    "    recall = [[] for i in K]\n",
    "    ids = [torch.tensor([]).to(feature.device) for i in K]\n",
    "    correct = [torch.tensor([]).to(feature.device) for i in K]\n",
    "    k_max = np.max(K)\n",
    "\n",
    "    # Collect predictions for classification report\n",
    "    all_preds = []\n",
    "\n",
    "    # Initialize dictionaries to store class-wise correct retrievals and total samples\n",
    "    num_classes = label.max().item() + 1\n",
    "    class_correct = {k: torch.zeros(num_classes).to(feature.device) for k in K}\n",
    "    class_total = torch.zeros(num_classes).to(feature.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j in range(chunks):\n",
    "            torch.cuda.empty_cache()\n",
    "            part_feature = feat_norm[split[j]: split[j + 1]]\n",
    "            similarity = torch.einsum('ab,bc->ac', part_feature, feat_norm.T)\n",
    "\n",
    "            topmax = similarity.topk(k_max + 1)[1][:, 1:]\n",
    "            del similarity\n",
    "            retrievalmax = label[topmax].squeeze()\n",
    "            for k, i in enumerate(K):\n",
    "                anchor_label = label[split[j]: split[j + 1]].repeat(1, i)\n",
    "                topi = topmax[:, :i]\n",
    "                retrieval_label = retrievalmax[:, :i]\n",
    "                correct_i = torch.sum(anchor_label == retrieval_label, dim=1, keepdim=True)\n",
    "                correct[k] = torch.cat([correct[k], correct_i], dim=0)\n",
    "                ids[k] = torch.cat([ids[k], topi], dim=0)\n",
    "\n",
    "                # Collect predictions for classification report\n",
    "                if k == 0:  # Assuming we want the predictions for the first K value\n",
    "                    all_preds.extend(retrieval_label[:, 0].cpu().numpy())\n",
    "\n",
    "                 # Update class-wise correct retrievals\n",
    "                for c in range(num_classes):\n",
    "                    class_mask = (anchor_label[:, 0] == c)\n",
    "                    class_correct[i][c] += torch.sum(correct_i[class_mask])\n",
    "\n",
    "            # Update class-wise total samples\n",
    "            for c in range(num_classes):\n",
    "                class_total[c] += torch.sum(label[split[j]: split[j + 1]] == c)\n",
    "                print(f\"Class {c}: {class_correct[1][c]} / {class_total[c]}\")\n",
    "\n",
    "        # Calculate recall @ K for each class\n",
    "        # recall_per_class = {k: torch.zeros(num_classes) for k in K}\n",
    "        recall_per_class = {k: {} for k in K}\n",
    "        for k in K:\n",
    "            for c in range(num_classes):\n",
    "                recall_per_class[k][c] = float((class_correct[k][c] > 0).int().sum() / class_total[c])\n",
    "                # if class_total[c] > 0:\n",
    "                #     recall_per_class[k][c] = (class_correct[k][c] / class_total[c]).item()\n",
    "                # else:\n",
    "                #     recall_per_class[k][c] = 0.0\n",
    "        print(recall_per_class)\n",
    "\n",
    "        # Print Recall@k for each class\n",
    "        # for k in K:\n",
    "        #     print(f\"\\nRecall@{k} for each class:\")\n",
    "        #     for c in range(num_classes):\n",
    "        #         print(f\"Class {c}: {recall_per_class[k][c]:.4f}\")\n",
    "\n",
    "        # calculate recall @ K\n",
    "        num_sample = len(feat_norm)\n",
    "        for k, i in enumerate(K):\n",
    "            acc_k = float((correct[k] > 0).int().sum() / num_sample)\n",
    "            recall[k] = acc_k\n",
    "\n",
    "    # Generate classification report\n",
    "    y_true = label.cpu().numpy().flatten()\n",
    "    y_pred = np.array(all_preds)\n",
    "    class_report = classification_report(y_true, y_pred, digits=4, zero_division=0)\n",
    "\n",
    "\n",
    "    if not args.NO_TSNE:\n",
    "\n",
    "        # Initialize lists to store the subsets\n",
    "        feature_subset_list = []\n",
    "        label_subset_list = []\n",
    "\n",
    "        # Get unique labels\n",
    "        unique_labels = torch.unique(label)\n",
    "\n",
    "        # Iterate over each unique label\n",
    "        for unique_label in unique_labels:\n",
    "            # Get indices of samples with the current label\n",
    "            label_indices = (label == unique_label).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # Select the first 100 samples (or fewer if less than 100 samples are available)\n",
    "            selected_indices = label_indices[:num_samples]\n",
    "            \n",
    "            # Append the selected features and labels to the lists\n",
    "            feature_subset_list.append(feat_norm[selected_indices])\n",
    "            label_subset_list.append(label[selected_indices])\n",
    "\n",
    "        # Concatenate the lists to form the final subsets\n",
    "        feature_subset = torch.cat(feature_subset_list, dim=0)\n",
    "        label_subset = torch.cat(label_subset_list, dim=0)\n",
    "        \n",
    "        # Apply t-SNE on the subset of features\n",
    "        tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "        tsne_features = tsne.fit_transform(feature_subset.cpu().numpy())\n",
    "        tsne_labels = label_subset.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "        # tSNE save path\n",
    "        tsne_save_path = os.path.join(args.logs, args.results_dir, 'test_TSNE')\n",
    "\n",
    "        if not os.path.exists(tsne_save_path):\n",
    "            os.mkdir(tsne_save_path)\n",
    "\n",
    "        # Plot t-SNE\n",
    "        #  dont show the plot only save\n",
    "        colors = ['#FF1B1B', '#229122', '#0909FF', '#0DC2C2', '#C107C1', '#BFBF01', '#040404', '#F091F0']\n",
    "\n",
    "        plt.ioff()\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=tsne_labels, cmap=ListedColormap(colors))\n",
    "        # Get unique labels\n",
    "        unique_labels = np.unique(tsne_labels)\n",
    "        # Create legend patches\n",
    "        legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i], markersize=10, label=f'{i}') for i in unique_labels]\n",
    "        # Add legend to plot\n",
    "        plt.legend(handles=legend_patches, title=\"Classes\", loc='upper left')\n",
    "\n",
    "        plt.title(f't-SNE visualization {args.dataset}')\n",
    "        plt.savefig(os.path.join(tsne_save_path, f'tsne_epoch_{epoch}.png'))\n",
    "\n",
    "    return recall, recall_per_class, class_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4d4acba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_proc(args, model, train_loader, test_loader):\n",
    "    \"\"\"### Start testing\"\"\"\n",
    "    # define optimizer\n",
    "    epoch_start = 0\n",
    "\n",
    "    test_logs = open(f'{args.logs}/{args.results_dir}/test_logs.txt', 'w')\n",
    "\n",
    "    # training loop\n",
    "    best_retrieval_top1 = 0\n",
    "    best_retrieval_top2 = 0\n",
    "    best_retrieval_top5 = 0\n",
    "    best_retrieval_top10 = 0\n",
    "    best_retrieval_top50 = 0\n",
    "    best_retrieval_top100 = 0\n",
    "\n",
    "    model.initiate_memorybank(train_loader)\n",
    "\n",
    "    for epoch in range(epoch_start, args.epochs):\n",
    "        if epoch % 1 == 0:\n",
    "            # weight save path\n",
    "            weight_save_path = os.path.join(args.logs, args.results_dir, 'weight')\n",
    "            model_save_path = os.path.join(weight_save_path, f'model_epoch_{epoch}.pth')\n",
    "            # print(f'loading model from {model_save_path}')\n",
    "            model_state_dict = torch.load(model_save_path)\n",
    "            model.load_state_dict(model_state_dict)\n",
    "            print(f'loaded successfully = {model_save_path}')\n",
    "            \n",
    "            retrieval_topk, retrieval_topk_perclass, class_report = test_retrieval(encoder=model.encoder_q, test_loader=test_loader, K=[1, 2, 5, 10, 50, 100], args=args, epoch=epoch, chunks=10)\n",
    "            retrieval_top1, retrieval_top2, retrieval_top5, retrieval_top10, retrieval_top50, retrieval_top100 = retrieval_topk\n",
    "            if retrieval_top1 > best_retrieval_top1:\n",
    "                best_retrieval_top1 = best_retrieval_top1\n",
    "            if retrieval_top2 > best_retrieval_top2:\n",
    "                best_retrieval_top2 = best_retrieval_top2\n",
    "            if retrieval_top5 > best_retrieval_top5:\n",
    "                best_retrieval_top5 = best_retrieval_top5\n",
    "            if retrieval_top10 > best_retrieval_top10:\n",
    "                best_retrieval_top10 = best_retrieval_top10\n",
    "            if retrieval_top50 > best_retrieval_top50:\n",
    "                best_retrieval_top50 = best_retrieval_top50\n",
    "            if retrieval_top100 > best_retrieval_top100:\n",
    "                best_retrieval_top100 = best_retrieval_top100\n",
    "\n",
    "            # save statistics\n",
    "            print(f'Epoch [{epoch}/{args.epochs}]: R@1: {retrieval_top1:.4f}, R@2: {retrieval_top2:.4f}, R@5: {retrieval_top5:.4f}, R@10: {retrieval_top10:.4f},  R@50: {retrieval_top50:.4f},R@100: {retrieval_top100:.4f}')\n",
    "            test_logs.write(f'Epoch [{epoch}/{args.epochs}]:\\n')\n",
    "            test_logs.write(f'    R@1: {retrieval_top1:.4f}, R@2: {retrieval_top2:.4f}, R@5: {retrieval_top5:.4f}, R@10: {retrieval_top10:.4f},  R@50: {retrieval_top50:.4f},R@100: {retrieval_top100:.4f}\\n')\n",
    "\n",
    "            headers = \"    \".join([f\"Per_Class R@{k}:\" for k in retrieval_topk_perclass.keys()])\n",
    "            test_logs.write(headers + \"\\n\")\n",
    "\n",
    "            # Get the maximum number of classes\n",
    "            max_classes = max(len(v) for v in retrieval_topk_perclass.values())\n",
    "\n",
    "            for class_id in range(max_classes):\n",
    "                line = []\n",
    "                for k in retrieval_topk_perclass.keys():\n",
    "                    if class_id in retrieval_topk_perclass[k]:\n",
    "                        line.append(f\"Class-{class_id}: {retrieval_topk_perclass[k][class_id]:.4f}\")\n",
    "                    else:\n",
    "                        line.append(f\"Class-{class_id}: N/A\")\n",
    "                test_logs.write(\"    \".join(line) + \"\\n\")\n",
    "            \n",
    "            test_logs.write(\"\\n\")\n",
    "\n",
    "            test_logs.write(f\"Classification Report:\\n{class_report}\\n\")\n",
    "            \n",
    "            test_logs.flush()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "63d174ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    args = parser.parse_args([\n",
    "                                '--epochs','500',\n",
    "                                '--dataset', 'cifartoy_bad',\n",
    "                                '--NO_TSNE', # Action argument to disable t-SNE visualization\n",
    "                            ])\n",
    "    \n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    random.seed(1228)\n",
    "    torch.manual_seed(1228)\n",
    "    torch.cuda.manual_seed_all(1228)\n",
    "    np.random.seed(1228)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    \"\"\"Define train/test\"\"\"\n",
    "    query_transform = get_augment(args.dataset, args.aug_q)\n",
    "    key_transform = get_augment(args.dataset, args.aug_k)\n",
    "    test_transform = get_augment(args.dataset)\n",
    "\n",
    "    if args.dataset == 'cars196':\n",
    "        train_dataset = CARS196(root=args.data_path, split='train', transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = CARS196(root=args.data_path, split='test', transform=test_transform)\n",
    "        args.num_classes = 8\n",
    "        args.size = 224\n",
    "\n",
    "    elif args.dataset == 'cifar100':\n",
    "        train_dataset = CIFAR100(root=args.data_path, download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = CIFAR100(root=args.data_path, train=False, download=True, transform=test_transform)\n",
    "        args.num_classes = 20\n",
    "        args.size = 32\n",
    "\n",
    "    elif args.dataset == 'cifartoy_good':\n",
    "        train_dataset = CIFARtoy(root=args.data_path, split='good', download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = CIFARtoy(root=args.data_path, split='good', train=False, download=True, transform=test_transform)\n",
    "        args.num_classes = 2\n",
    "        args.size = 32\n",
    "\n",
    "    elif args.dataset == 'cifartoy_bad':\n",
    "        train_dataset = CIFARtoy(root=args.data_path, split='bad', download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = CIFARtoy(root=args.data_path, split='bad', train=False, download=True, transform=test_transform)\n",
    "        args.num_classes = 2\n",
    "        args.size = 32\n",
    "\n",
    "    elif args.dataset == 'sop_split2':\n",
    "        train_dataset = StanfordOnlineProducts(split='2', root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = StanfordOnlineProducts(split='2', root=args.data_path, train=False, transform=test_transform)\n",
    "        args.num_classes = 12\n",
    "        args.size = 224\n",
    "\n",
    "    elif args.dataset == 'sop_split1':\n",
    "        train_dataset = StanfordOnlineProducts(split='1', root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = StanfordOnlineProducts(split='1', root=args.data_path, train=False, transform=test_transform)\n",
    "        args.num_classes = 12\n",
    "        args.size = 224\n",
    "\n",
    "    elif args.dataset == 'imagenet32':\n",
    "        train_dataset = ImageNetDownSample(root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "        test_dataset = ImageNetDownSample(root=args.data_path, train=False, transform=test_transform)\n",
    "        args.num_classes = 12\n",
    "        args.size = 32\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'{args.dataset} is not supported now!')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # create trainer\n",
    "    trainer = MaskCon(num_classes_coarse=args.num_classes, dim=args.dim, K=args.K, m=args.m, T1=args.t0, arch=args.arch, size=args.size, T2=args.t, mode=args.mode).cuda()\n",
    "\n",
    "    # create logs directory\n",
    "    now = datetime.datetime.now().strftime('%y%m%d-%p%I%M')\n",
    "    args.results_dir = f'240627-PM0412-arch_{args.arch}-data_{args.dataset}-{args.mode}'\n",
    "\n",
    "    if not os.path.exists(args.logs):\n",
    "        os.mkdir(args.logs)\n",
    "    if not os.path.exists(f'{args.logs}/{args.results_dir}'):\n",
    "        # Give an error message\n",
    "        print(f'No logs found in {args.logs}/{args.results_dir}')\n",
    "        return None\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    test_proc(args, trainer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c0749671",
   "metadata": {
    "papermill": {
     "duration": 14.072521,
     "end_time": "2024-06-27T12:22:47.704866",
     "exception": false,
     "start_time": "2024-06-27T12:22:33.632345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knoor/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/knoor/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cifartoy_bad', data_path='./data', arch='resnet18', dim=256, K=8192, m=0.99, t0=0.1, lr=0.02, epochs=500, warm_up=5, batch_size=128, wd=0.0005, aug_q='strong', aug_k='weak', gpu_id='0', mode='maskcon', w=0.5, t=0.05, logs='logs', NO_TSNE=True, num_classes=2, size=32, results_dir='240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon')\n",
      "Initiate memory bank!\n",
      "loaded successfully = logs/240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon/weight/model_epoch_0.pth\n",
      "Class 0: 458.0 / 800.0\n",
      "Class 1: 0.0 / 0.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 329.0 / 600.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 183.0 / 400.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 69.0 / 200.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 475.0 / 800.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 584.0 / 1000.0\n",
      "Class 5: 313.0 / 600.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 187.0 / 400.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 584.0 / 1000.0\n",
      "Class 5: 516.0 / 1000.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 475.0 / 1000.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 584.0 / 1000.0\n",
      "Class 5: 516.0 / 1000.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 112.0 / 200.0\n",
      "Class 0: 564.0 / 1000.0\n",
      "Class 1: 546.0 / 1000.0\n",
      "Class 2: 475.0 / 1000.0\n",
      "Class 3: 327.0 / 1000.0\n",
      "Class 4: 584.0 / 1000.0\n",
      "Class 5: 516.0 / 1000.0\n",
      "Class 6: 455.0 / 1000.0\n",
      "Class 7: 541.0 / 1000.0\n",
      "{1: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 2: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 5: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 10: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 50: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 100: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}}\n",
      "Epoch [0/500]: R@1: 0.5010, R@2: 0.6614, R@5: 0.8384, R@10: 0.9221,  R@50: 0.9930,R@100: 0.9981\n",
      "loaded successfully = logs/240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon/weight/model_epoch_1.pth\n",
      "Class 0: 522.0 / 800.0\n",
      "Class 1: 0.0 / 0.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 395.0 / 600.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 202.0 / 400.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 91.0 / 200.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 551.0 / 800.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 689.0 / 1000.0\n",
      "Class 5: 385.0 / 600.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 227.0 / 400.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 689.0 / 1000.0\n",
      "Class 5: 642.0 / 1000.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 551.0 / 1000.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 689.0 / 1000.0\n",
      "Class 5: 642.0 / 1000.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 137.0 / 200.0\n",
      "Class 0: 666.0 / 1000.0\n",
      "Class 1: 660.0 / 1000.0\n",
      "Class 2: 551.0 / 1000.0\n",
      "Class 3: 429.0 / 1000.0\n",
      "Class 4: 689.0 / 1000.0\n",
      "Class 5: 642.0 / 1000.0\n",
      "Class 6: 511.0 / 1000.0\n",
      "Class 7: 678.0 / 1000.0\n",
      "{1: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 2: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 5: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 10: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 50: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 100: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}}\n",
      "Epoch [1/500]: R@1: 0.6033, R@2: 0.7514, R@5: 0.8871, R@10: 0.9425,  R@50: 0.9941,R@100: 0.9983\n",
      "loaded successfully = logs/240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon/weight/model_epoch_2.pth\n",
      "Class 0: 537.0 / 800.0\n",
      "Class 1: 0.0 / 0.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 466.0 / 600.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 240.0 / 400.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 98.0 / 200.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 627.0 / 800.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 793.0 / 1000.0\n",
      "Class 5: 428.0 / 600.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 234.0 / 400.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 793.0 / 1000.0\n",
      "Class 5: 727.0 / 1000.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 592.0 / 1000.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 793.0 / 1000.0\n",
      "Class 5: 727.0 / 1000.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 150.0 / 200.0\n",
      "Class 0: 673.0 / 1000.0\n",
      "Class 1: 756.0 / 1000.0\n",
      "Class 2: 592.0 / 1000.0\n",
      "Class 3: 472.0 / 1000.0\n",
      "Class 4: 793.0 / 1000.0\n",
      "Class 5: 727.0 / 1000.0\n",
      "Class 6: 602.0 / 1000.0\n",
      "Class 7: 751.0 / 1000.0\n",
      "{1: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 2: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 5: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 10: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 50: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 100: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}}\n",
      "Epoch [2/500]: R@1: 0.6708, R@2: 0.7939, R@5: 0.9048, R@10: 0.9518,  R@50: 0.9948,R@100: 0.9981\n",
      "loaded successfully = logs/240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon/weight/model_epoch_3.pth\n",
      "Class 0: 605.0 / 800.0\n",
      "Class 1: 0.0 / 0.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 494.0 / 600.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 245.0 / 400.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 105.0 / 200.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 658.0 / 800.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 830.0 / 1000.0\n",
      "Class 5: 478.0 / 600.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 248.0 / 400.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 830.0 / 1000.0\n",
      "Class 5: 809.0 / 1000.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 646.0 / 1000.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 830.0 / 1000.0\n",
      "Class 5: 809.0 / 1000.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 162.0 / 200.0\n",
      "Class 0: 765.0 / 1000.0\n",
      "Class 1: 821.0 / 1000.0\n",
      "Class 2: 646.0 / 1000.0\n",
      "Class 3: 528.0 / 1000.0\n",
      "Class 4: 830.0 / 1000.0\n",
      "Class 5: 809.0 / 1000.0\n",
      "Class 6: 606.0 / 1000.0\n",
      "Class 7: 810.0 / 1000.0\n",
      "{1: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 2: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 5: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 10: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 50: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 100: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}}\n",
      "Epoch [3/500]: R@1: 0.7269, R@2: 0.8309, R@5: 0.9203, R@10: 0.9589,  R@50: 0.9953,R@100: 0.9986\n",
      "loaded successfully = logs/240627-PM0412-arch_resnet18-data_cifartoy_bad-maskcon/weight/model_epoch_4.pth\n",
      "Class 0: 599.0 / 800.0\n",
      "Class 1: 0.0 / 0.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 519.0 / 600.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 0.0 / 0.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 0.0 / 0.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 258.0 / 400.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 113.0 / 200.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 0.0 / 0.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 662.0 / 800.0\n",
      "Class 5: 0.0 / 0.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 0.0 / 0.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 828.0 / 1000.0\n",
      "Class 5: 478.0 / 600.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 268.0 / 400.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 828.0 / 1000.0\n",
      "Class 5: 812.0 / 1000.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 0.0 / 0.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 678.0 / 1000.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 828.0 / 1000.0\n",
      "Class 5: 812.0 / 1000.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 153.0 / 200.0\n",
      "Class 0: 759.0 / 1000.0\n",
      "Class 1: 851.0 / 1000.0\n",
      "Class 2: 678.0 / 1000.0\n",
      "Class 3: 550.0 / 1000.0\n",
      "Class 4: 828.0 / 1000.0\n",
      "Class 5: 812.0 / 1000.0\n",
      "Class 6: 655.0 / 1000.0\n",
      "Class 7: 780.0 / 1000.0\n",
      "{1: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 2: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 5: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 10: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 50: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}, 100: {0: 0.0010000000474974513, 1: 0.0010000000474974513, 2: 0.0010000000474974513, 3: 0.0010000000474974513, 4: 0.0010000000474974513, 5: 0.0010000000474974513, 6: 0.0010000000474974513, 7: 0.0010000000474974513}}\n",
      "Epoch [4/500]: R@1: 0.7391, R@2: 0.8426, R@5: 0.9331, R@10: 0.9628,  R@50: 0.9954,R@100: 0.9991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[192], line 87\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mtest_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[191], line 25\u001b[0m, in \u001b[0;36mtest_proc\u001b[0;34m(args, model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(f'loading model from {model_save_path}')\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_save_path)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded successfully = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m retrieval_topk, retrieval_topk_perclass, class_report \u001b[38;5;241m=\u001b[39m test_retrieval(encoder\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder_q, test_loader\u001b[38;5;241m=\u001b[39mtest_loader, K\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m], args\u001b[38;5;241m=\u001b[39margs, epoch\u001b[38;5;241m=\u001b[39mepoch, chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1590\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         out \u001b[38;5;241m=\u001b[39m hook(module, incompatible_keys)\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[1;32m   1585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1586\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit should be done inplace.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1588\u001b[0m         )\n\u001b[0;32m-> 1590\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m load\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "File \u001b[0;32m~/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1578\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[0;32m~/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1578\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[0;32m~/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1574\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(module, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1573\u001b[0m     local_metadata \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget(prefix[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], {})\n\u001b[0;32m-> 1574\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1577\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/knoor_torch-v1.12.1/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1528\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m extra_state_key:\n\u001b[1;32m   1529\u001b[0m             input_name \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;28mlen\u001b[39m(prefix):]\n\u001b[1;32m   1530\u001b[0m             input_name \u001b[38;5;241m=\u001b[39m input_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# get the name of param/buffer/child\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40e8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd5d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22272.729377,
   "end_time": "2024-06-27T12:23:05.595309",
   "environment_variables": {},
   "exception": null,
   "input_path": "cifartoy_bad_500.ipynb",
   "output_path": "cifartoy_bad_500.ipynb",
   "parameters": {},
   "start_time": "2024-06-27T06:11:52.865932",
   "version": "2.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
