{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf58b62",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [12]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ed040",
   "metadata": {
    "papermill": {
     "duration": 0.075688,
     "end_time": "2024-06-20T06:20:05.005226",
     "exception": false,
     "start_time": "2024-06-20T06:20:04.929538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc196e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:20:05.043984Z",
     "iopub.status.busy": "2024-06-20T06:20:05.043115Z",
     "iopub.status.idle": "2024-06-20T06:20:05.224054Z",
     "shell.execute_reply": "2024-06-20T06:20:05.222825Z"
    },
    "papermill": {
     "duration": 0.193135,
     "end_time": "2024-06-20T06:20:05.226545",
     "exception": false,
     "start_time": "2024-06-20T06:20:05.033410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/knoor/.conda/envs/tf28_luthin/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "/bin/bash: nvcc: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a3233b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:20:05.287073Z",
     "iopub.status.busy": "2024-06-20T06:20:05.286597Z",
     "iopub.status.idle": "2024-06-20T06:22:07.737677Z",
     "shell.execute_reply": "2024-06-20T06:22:07.736787Z"
    },
    "papermill": {
     "duration": 122.4982,
     "end_time": "2024-06-20T06:22:07.740352",
     "exception": false,
     "start_time": "2024-06-20T06:20:05.242152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe39d1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:07.878607Z",
     "iopub.status.busy": "2024-06-20T06:22:07.878221Z",
     "iopub.status.idle": "2024-06-20T06:22:07.882597Z",
     "shell.execute_reply": "2024-06-20T06:22:07.881911Z"
    },
    "papermill": {
     "duration": 0.06899,
     "end_time": "2024-06-20T06:22:07.885143",
     "exception": false,
     "start_time": "2024-06-20T06:22:07.816153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf68235a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:08.521985Z",
     "iopub.status.busy": "2024-06-20T06:22:08.521652Z",
     "iopub.status.idle": "2024-06-20T06:22:08.538462Z",
     "shell.execute_reply": "2024-06-20T06:22:08.537704Z"
    },
    "papermill": {
     "duration": 0.620596,
     "end_time": "2024-06-20T06:22:08.540188",
     "exception": false,
     "start_time": "2024-06-20T06:22:07.919592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--logs'], dest='logs', nargs=None, const=None, default='logs', type=<class 'str'>, choices=None, required=False, help='log directory file name', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for jupyter notebook set arguments\n",
    "parser = argparse.ArgumentParser(description='Masked contrastive learning.')\n",
    "args = argparse.Namespace(description='Masked contrastive learning.')\n",
    "\n",
    "# training config:\n",
    "parser.add_argument('--dataset', default='cifartoy_good', choices=['cifar100', 'cifartoy_bad', 'cifartoy_good', 'cars196', 'sop_split1', 'sop_split2', 'imagenet32'], type=str, help='train dataset')\n",
    "parser.add_argument('--data_path', default='./data', type=str, help='train dataset')\n",
    "\n",
    "# model configs: [Almost fixed for all experiments]\n",
    "parser.add_argument('--arch', default='resnet18')\n",
    "parser.add_argument('--dim', default=256, type=int, help='feature dimension')\n",
    "parser.add_argument('--K', default=8192, type=int, help='queue size; number of negative keys')\n",
    "parser.add_argument('--m', default=0.99, type=float, help='moco momentum of updating key encoder')\n",
    "parser.add_argument('--t0', default=0.1, type=float, help='softmax temperature for training')\n",
    "\n",
    "# train configs:\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.02, type=float, metavar='LR', help='initial learning rate', dest='lr')\n",
    "# parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs')\n",
    "parser.add_argument('--epochs', default=300, type=int, metavar='N', help='number of total epochs')\n",
    "parser.add_argument('--warm_up', default=5, type=int, metavar='N', help='number of warmup epochs')\n",
    "parser.add_argument('--batch_size', default=128, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "parser.add_argument('--aug_q', default='strong', type=str, help='augmentation strategy for query image')\n",
    "parser.add_argument('--aug_k', default='weak', type=str, help='augmentation strategy for key image')\n",
    "parser.add_argument('--gpu_id', default='0', type=str, help='gpuid')\n",
    "\n",
    "# method configs:\n",
    "parser.add_argument('--mode', default='maskcon', type=str, choices=['maskcon', 'grafit', 'coins'], help='training mode')\n",
    "\n",
    "# maskcon-specific hyperparameters:\n",
    "parser.add_argument('--w', default=0.5, type=float, help='weight of self-invariance')  # not-used if maskcon\n",
    "parser.add_argument('--t', default=0.05, type=float, help='softmax temperature weight for soft label')\n",
    "\n",
    "# logger configs\n",
    "# parser.add_argument('--wandb_id', default='logs',type=str, help='wandb user id')\n",
    "parser.add_argument('--logs', default='logs',type=str, help='log directory file name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fe33d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:08.559685Z",
     "iopub.status.busy": "2024-06-20T06:22:08.559371Z",
     "iopub.status.idle": "2024-06-20T06:22:08.569217Z",
     "shell.execute_reply": "2024-06-20T06:22:08.568345Z"
    },
    "papermill": {
     "duration": 0.02121,
     "end_time": "2024-06-20T06:22:08.571192",
     "exception": false,
     "start_time": "2024-06-20T06:22:08.549982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train(net, data_loader, train_optimizer, epoch, args):\n",
    "    net.train()\n",
    "    losses, total_num = 0.0, 0.0\n",
    "    train_bar = tqdm(data_loader)\n",
    "    for i, [[im_k, im_q], coarse_targets, fine_targets] in enumerate(train_bar):\n",
    "        adjust_learning_rate(train_optimizer, args.warm_up, epoch, args.epochs, args.lr, i, data_loader.__len__())\n",
    "        im_k, im_q, coarse_targets, fine_targets = im_k.cuda(), im_q.cuda(), coarse_targets.cuda(), fine_targets.cuda()\n",
    "        if args.mode == 'grafit' or args.mode == 'coins':\n",
    "            loss = net.forward_explicit(im_k, im_q, coarse_targets, args)\n",
    "        else:  # if args.mode == 'maskcon'\n",
    "            loss = net(im_k, im_q, coarse_targets, args)\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += im_k.shape[0]\n",
    "        losses += loss.item() * im_k.shape[0]\n",
    "        train_bar.set_description(\n",
    "            'Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(\n",
    "                epoch, args.epochs,\n",
    "                train_optimizer.param_groups[0]['lr'],\n",
    "                losses / total_num\n",
    "            ))\n",
    "        \n",
    "    # Save model weights after each epoch\n",
    "    model_save_path = os.path.join(args.logs, args.results_dir, f'model_epoch_{epoch}.pth')\n",
    "    torch.save(net.state_dict(), model_save_path)\n",
    "\n",
    "    return losses / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0f97ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:08.677542Z",
     "iopub.status.busy": "2024-06-20T06:22:08.677212Z",
     "iopub.status.idle": "2024-06-20T06:22:08.687181Z",
     "shell.execute_reply": "2024-06-20T06:22:08.686441Z"
    },
    "papermill": {
     "duration": 0.049865,
     "end_time": "2024-06-20T06:22:08.689152",
     "exception": false,
     "start_time": "2024-06-20T06:22:08.639287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train(net, data_loader, train_optimizer, epoch, args):\n",
    "    net.train()\n",
    "    losses, total_num = 0.0, 0.0\n",
    "    train_bar = tqdm(data_loader)\n",
    "    for i, [[im_k, im_q], coarse_targets, fine_targets] in enumerate(train_bar):\n",
    "        adjust_learning_rate(train_optimizer, args.warm_up, epoch, args.epochs, args.lr, i, data_loader.__len__())\n",
    "        im_k, im_q, coarse_targets, fine_targets = im_k.cuda(), im_q.cuda(), coarse_targets.cuda(), fine_targets.cuda()\n",
    "        if args.mode == 'grafit' or args.mode == 'coins':\n",
    "            loss = net.forward_explicit(im_k, im_q, coarse_targets, args)\n",
    "        else:  # if args.mode == 'maskcon'\n",
    "            loss = net(im_k, im_q, coarse_targets, args)\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += im_k.shape[0]\n",
    "        losses += loss.item() * im_k.shape[0]\n",
    "        train_bar.set_description(\n",
    "            'Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(\n",
    "                epoch, args.epochs,\n",
    "                train_optimizer.param_groups[0]['lr'],\n",
    "                losses / total_num\n",
    "            ))\n",
    "        \n",
    "    # Save model weights after each epoch\n",
    "    model_save_path = os.path.join(args.logs, args.results_dir, f'model_epoch_{epoch}.pth')\n",
    "    torch.save(net.state_dict(), model_save_path)\n",
    "\n",
    "    return losses / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d36e207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:08.841763Z",
     "iopub.status.busy": "2024-06-20T06:22:08.841560Z",
     "iopub.status.idle": "2024-06-20T06:22:08.851856Z",
     "shell.execute_reply": "2024-06-20T06:22:08.851114Z"
    },
    "papermill": {
     "duration": 0.024157,
     "end_time": "2024-06-20T06:22:08.853824",
     "exception": false,
     "start_time": "2024-06-20T06:22:08.829667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieval(encoder, test_loader, K, args, epoch, chunks=10, num_samples=1000):\n",
    "    encoder.eval()\n",
    "    feature_bank, target_bank = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (image, _, fine_label) in enumerate(test_loader):\n",
    "            image = image.cuda(non_blocking=True)\n",
    "            label = fine_label.cuda(non_blocking=True)\n",
    "            output = encoder(image, feat=True)\n",
    "            feature_bank.append(output)\n",
    "            target_bank.append(label)\n",
    "        \n",
    "        feature = torch.cat(feature_bank, dim=0)\n",
    "        label = torch.cat(target_bank, dim=0).contiguous()\n",
    "        \n",
    "        # Randomly select a subset of samples\n",
    "        indices = torch.randperm(feature.size(0))[:num_samples]\n",
    "        feature_subset = feature[indices]\n",
    "        label_subset = label[indices]\n",
    "        \n",
    "        # Apply t-SNE on the subset of features\n",
    "        tsne = TSNE(n_components=2, random_state=0)\n",
    "        tsne_features = tsne.fit_transform(feature_subset.cpu().numpy())\n",
    "        tsne_labels = label_subset.cpu().numpy()\n",
    "    \n",
    "    label = label.unsqueeze(-1)\n",
    "    feat_norm = F.normalize(feature, dim=1)\n",
    "    split = torch.tensor(np.linspace(0, len(feat_norm), chunks + 1, dtype=int), dtype=torch.long).to(feature.device)\n",
    "    recall = [[] for i in K]\n",
    "    ids = [torch.tensor([]).to(feature.device) for i in K]\n",
    "    correct = [torch.tensor([]).to(feature.device) for i in K]\n",
    "    k_max = np.max(K)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j in range(chunks):\n",
    "            torch.cuda.empty_cache()\n",
    "            part_feature = feat_norm[split[j]: split[j + 1]]\n",
    "            similarity = torch.einsum('ab,bc->ac', part_feature, feat_norm.T)\n",
    "\n",
    "            topmax = similarity.topk(k_max + 1)[1][:, 1:]\n",
    "            del similarity\n",
    "            retrievalmax = label[topmax].squeeze()\n",
    "            for k, i in enumerate(K):\n",
    "                anchor_label = label[split[j]: split[j + 1]].repeat(1, i)\n",
    "                topi = topmax[:, :i]\n",
    "                retrieval_label = retrievalmax[:, :i]\n",
    "                correct_i = torch.sum(anchor_label == retrieval_label, dim=1, keepdim=True)\n",
    "                correct[k] = torch.cat([correct[k], correct_i], dim=0)\n",
    "                ids[k] = torch.cat([ids[k], topi], dim=0)\n",
    "\n",
    "        # calculate recall @ K\n",
    "        num_sample = len(feat_norm)\n",
    "        for k, i in enumerate(K):\n",
    "            acc_k = float((correct[k] > 0).int().sum() / num_sample)\n",
    "            recall[k] = acc_k\n",
    "\n",
    "    # Plot t-SNE\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(np.unique(tsne_labels))))\n",
    "    for label, color in zip(np.unique(tsne_labels), colors):\n",
    "        mask = tsne_labels == label\n",
    "        plt.scatter(tsne_features[mask, 0], tsne_features[mask, 1], color=color, label=label)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(f'{args.logs}/{args.results_dir}/tsne-epoch-{epoch}.png')\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65706fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:08.960259Z",
     "iopub.status.busy": "2024-06-20T06:22:08.959927Z",
     "iopub.status.idle": "2024-06-20T06:22:08.971908Z",
     "shell.execute_reply": "2024-06-20T06:22:08.971271Z"
    },
    "papermill": {
     "duration": 0.058389,
     "end_time": "2024-06-20T06:22:08.973925",
     "exception": false,
     "start_time": "2024-06-20T06:22:08.915536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_proc(args, model, train_loader, test_loader):\n",
    "    # wandb.init(project=args.mode, name='train_' + args.results_dir, group=f'train_{args.dataset}_{args.mode}')\n",
    "    # wandb.init(project=args.mode, entity=args.wandb_id, name='train_' + args.results_dir, group=f'train_{args.dataset}_{args.mode}')\n",
    "    # wandb.config.update(args)\n",
    "    \"\"\"### Start training\"\"\"\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wd, momentum=0.9)\n",
    "    epoch_start = 0\n",
    "\n",
    "    with open(f'{args.logs}/{args.results_dir}' + '/args.json', 'w') as fid:\n",
    "        json.dump(args.__dict__, fid, indent=2)\n",
    "\n",
    "    train_logs = open(f'{args.logs}/{args.results_dir}/train_logs.txt', 'w')\n",
    "\n",
    "    # training loop\n",
    "    best_retrieval_top1 = 0\n",
    "    best_retrieval_top2 = 0\n",
    "    best_retrieval_top5 = 0\n",
    "    best_retrieval_top10 = 0\n",
    "    best_retrieval_top50 = 0\n",
    "    best_retrieval_top100 = 0\n",
    "\n",
    "    model.initiate_memorybank(train_loader)\n",
    "\n",
    "    for epoch in range(epoch_start, args.epochs):\n",
    "        # retrieval_topk, tsne_features, tsne_labels = retrieval(model.encoder_q, test_loader, [0, 1, 2, 3, 4, 5])\n",
    "        if epoch % 10 == 0:\n",
    "            retrieval_topk = retrieval(encoder=model.encoder_q, test_loader=test_loader, K=[1, 2, 5, 10, 50, 100], args=args, epoch=epoch, chunks=10)\n",
    "            retrieval_top1, retrieval_top2, retrieval_top5, retrieval_top10, retrieval_top50, retrieval_top100 = retrieval_topk\n",
    "            if retrieval_top1 > best_retrieval_top1:\n",
    "                best_retrieval_top1 = best_retrieval_top1\n",
    "            if retrieval_top2 > best_retrieval_top2:\n",
    "                best_retrieval_top2 = best_retrieval_top2\n",
    "            if retrieval_top5 > best_retrieval_top5:\n",
    "                best_retrieval_top5 = best_retrieval_top5\n",
    "            if retrieval_top10 > best_retrieval_top10:\n",
    "                best_retrieval_top10 = best_retrieval_top10\n",
    "            if retrieval_top50 > best_retrieval_top50:\n",
    "                best_retrieval_top50 = best_retrieval_top50\n",
    "            if retrieval_top100 > best_retrieval_top100:\n",
    "                best_retrieval_top100 = best_retrieval_top100\n",
    "\n",
    "            # wandb.log({'R@1': retrieval_top1, 'R@2': retrieval_top2, 'R@5': retrieval_top5, 'R@10': retrieval_top10, 'R@50': retrieval_top50, 'R@100': retrieval_top100}, step=epoch)\n",
    "            # save statistics\n",
    "            print(f'Epoch [{epoch}/{args.epochs}]: R@1: {retrieval_top1:.4f}, R@2: {retrieval_top2:.4f}, R@5: {retrieval_top5:.4f}, R@10: {retrieval_top10:.4f},  R@50: {retrieval_top50:.4f},R@100: {retrieval_top100:.4f}')\n",
    "            # train_logs.write(\n",
    "            #     f'Epoch [{epoch}/{args.epochs}]: R@1: {retrieval_top1:.4f}, R@2: {retrieval_top2:.4f}, R@5: {retrieval_top5:.4f}, R@10: {retrieval_top10:.4f},  R@50: {retrieval_top50:.4f},R@100: {retrieval_top100:.4f}\\n')\n",
    "            # train_logs.flush()\n",
    "\n",
    "        train(model, train_loader, optimizer, epoch, args)\n",
    "    # wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e3cc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:09.006770Z",
     "iopub.status.busy": "2024-06-20T06:22:09.006623Z",
     "iopub.status.idle": "2024-06-20T06:22:09.010376Z",
     "shell.execute_reply": "2024-06-20T06:22:09.009717Z"
    },
    "papermill": {
     "duration": 0.016023,
     "end_time": "2024-06-20T06:22:09.012406",
     "exception": false,
     "start_time": "2024-06-20T06:22:08.996383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cifartoy_good', data_path='./data', arch='resnet18', dim=256, K=8192, m=0.99, t0=0.1, lr=0.02, epochs=300, warm_up=5, batch_size=128, wd=0.0005, aug_q='strong', aug_k='weak', gpu_id='0', mode='maskcon', w=0.5, t=0.05, logs='logs')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = parser.parse_args([])\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2292600e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:09.121700Z",
     "iopub.status.busy": "2024-06-20T06:22:09.121097Z",
     "iopub.status.idle": "2024-06-20T06:22:09.170737Z",
     "shell.execute_reply": "2024-06-20T06:22:09.169754Z"
    },
    "papermill": {
     "duration": 0.100045,
     "end_time": "2024-06-20T06:22:09.172839",
     "exception": false,
     "start_time": "2024-06-20T06:22:09.072794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "random.seed(1228)\n",
    "torch.manual_seed(1228)\n",
    "torch.cuda.manual_seed_all(1228)\n",
    "np.random.seed(1228)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd4bd97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:09.245264Z",
     "iopub.status.busy": "2024-06-20T06:22:09.244514Z",
     "iopub.status.idle": "2024-06-20T06:22:13.971912Z",
     "shell.execute_reply": "2024-06-20T06:22:13.970978Z"
    },
    "papermill": {
     "duration": 4.773334,
     "end_time": "2024-06-20T06:22:13.974324",
     "exception": false,
     "start_time": "2024-06-20T06:22:09.200990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Define train/test\"\"\"\n",
    "query_transform = get_augment(args.dataset, args.aug_q)\n",
    "key_transform = get_augment(args.dataset, args.aug_k)\n",
    "test_transform = get_augment(args.dataset)\n",
    "\n",
    "if args.dataset == 'cars196':\n",
    "    train_dataset = CARS196(root=args.data_path, split='train', transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = CARS196(root=args.data_path, split='test', transform=test_transform)\n",
    "    args.num_classes = 8\n",
    "    args.size = 224\n",
    "\n",
    "elif args.dataset == 'cifar100':\n",
    "    train_dataset = CIFAR100(root=args.data_path, download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = CIFAR100(root=args.data_path, train=False, download=True, transform=test_transform)\n",
    "    args.num_classes = 20\n",
    "    args.size = 32\n",
    "\n",
    "elif args.dataset == 'cifartoy_good':\n",
    "    train_dataset = CIFARtoy(root=args.data_path, split='good', download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = CIFARtoy(root=args.data_path, split='good', train=False, download=True, transform=test_transform)\n",
    "    args.num_classes = 2\n",
    "    args.size = 32\n",
    "\n",
    "elif args.dataset == 'cifartoy_bad':\n",
    "    train_dataset = CIFARtoy(root=args.data_path, split='bad', download=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = CIFARtoy(root=args.data_path, split='bad', train=False, download=True, transform=test_transform)\n",
    "    args.num_classes = 2\n",
    "    args.size = 32\n",
    "\n",
    "elif args.dataset == 'sop_split2':\n",
    "    train_dataset = StanfordOnlineProducts(split='2', root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = StanfordOnlineProducts(split='2', root=args.data_path, train=False, transform=test_transform)\n",
    "    args.num_classes = 12\n",
    "    args.size = 224\n",
    "\n",
    "elif args.dataset == 'sop_split1':\n",
    "    train_dataset = StanfordOnlineProducts(split='1', root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = StanfordOnlineProducts(split='1', root=args.data_path, train=False, transform=test_transform)\n",
    "    args.num_classes = 12\n",
    "    args.size = 224\n",
    "\n",
    "elif args.dataset == 'imagenet32':\n",
    "    train_dataset = ImageNetDownSample(root=args.data_path, train=True, transform=DMixTransform([key_transform, query_transform], [1, 1]))\n",
    "    test_dataset = ImageNetDownSample(root=args.data_path, train=False, transform=test_transform)\n",
    "    args.num_classes = 12\n",
    "    args.size = 32\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'{args.dataset} is not supported now!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750662b3",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167085fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:22:14.093298Z",
     "iopub.status.busy": "2024-06-20T06:22:14.092969Z",
     "iopub.status.idle": "2024-06-20T06:22:17.515182Z",
     "shell.execute_reply": "2024-06-20T06:22:17.514101Z"
    },
    "papermill": {
     "duration": 3.495927,
     "end_time": "2024-06-20T06:22:17.517372",
     "exception": true,
     "start_time": "2024-06-20T06:22:14.021445",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knoor/.conda/envs/pytorch_201/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/knoor/.conda/envs/pytorch_201/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create trainer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mMaskCon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes_coarse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# args.results_dir = f'arch_[{args.arch}]_data[{args.dataset}]_epochs[{args.epochs}]_memorysize[{args.K}]_mode[{args.mode}]_contrastive_temperature[{args.t0}]_temperature_maskcon[{args.t}]_weight[{args.w}]]'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m args\u001b[38;5;241m.\u001b[39mresults_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march_[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39march\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]_data[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]_epochs[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]_mode[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_201/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# create trainer\n",
    "trainer = MaskCon(num_classes_coarse=args.num_classes, dim=args.dim, K=args.K, m=args.m, T1=args.t0, arch=args.arch, size=args.size, T2=args.t, mode=args.mode).cuda()\n",
    "\n",
    "# args.results_dir = f'arch_[{args.arch}]_data[{args.dataset}]_epochs[{args.epochs}]_memorysize[{args.K}]_mode[{args.mode}]_contrastive_temperature[{args.t0}]_temperature_maskcon[{args.t}]_weight[{args.w}]]'\n",
    "args.results_dir = f'arch_[{args.arch}]_data[{args.dataset}]_epochs[{args.epochs}]_mode[{args.mode}]'\n",
    "\n",
    "if not os.path.exists(args.logs):\n",
    "    os.mkdir(args.logs)\n",
    "if not os.path.exists(f'{args.logs}/{args.results_dir}'):\n",
    "    os.mkdir(f'{args.logs}/{args.results_dir}')\n",
    "\n",
    "main_proc(args, trainer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0749671",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 165.214042,
   "end_time": "2024-06-20T06:22:19.764911",
   "environment_variables": {},
   "exception": true,
   "input_path": "cifartoy_good_2.ipynb",
   "output_path": "cifartoy_good_2.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T06:19:34.550869",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}